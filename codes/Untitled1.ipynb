{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a527196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from new_data import HSIDataLoader,TestDS, TrainDS\n",
    "import numpy as np\n",
    "from plot import show_tensor_image,show_spectral_curve\n",
    "from torch import nn\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361cf676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data] load data shape data=(145, 145, 200), label=(145, 145)\n",
      "[data] data patches shape data=(21025, 1, 1, 200), label=(21025,)\n",
      "------[data] after transpose train, test------\n",
      "X.shape= (21025, 200, 1, 1)\n",
      "Y.shape= (21025,)\n",
      "(21025, 1, 200) (21025,)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "dataloader = HSIDataLoader({})\n",
    "train_loader,X, Y = dataloader.generate_torch_dataset()\n",
    "newX = np.expand_dims(X.squeeze(),1)\n",
    "newX = newX * 2 - 1\n",
    "newY = Y\n",
    "all_data_loader = torch.utils.data.DataLoader(dataset=TrainDS(newX,newY),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=0)\n",
    "print(newX.shape, newY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8288f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class Diffusion(object):\n",
    "    def __init__(self) -> None:\n",
    "        self.T = 100\n",
    "        self.betas = self._linear_beta_schedule(timesteps=self.T)\n",
    "        # Pre-calculate different terms for closed form\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n",
    "        self.posterior_variance = self.betas * (1. - self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)\n",
    "\n",
    "\n",
    "    def _linear_beta_schedule(self, timesteps, start=0.0001, end=0.02):\n",
    "        return torch.linspace(start, end, timesteps)\n",
    "\n",
    "    def _get_index_from_list(self, vals, t, x_shape):\n",
    "        \"\"\" \n",
    "        Returns a specific index t of a passed list of values vals\n",
    "        while considering the batch dimension.\n",
    "        \"\"\"\n",
    "        batch_size = t.shape[0]\n",
    "        out = vals.gather(-1, t.cpu())\n",
    "        return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
    "\n",
    "    def forward_diffusion_sample(self, x_0, t, device=\"cpu\"):\n",
    "        \"\"\" \n",
    "        Takes an image and a timestep as input and \n",
    "        returns the noisy version of it\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(x_0)\n",
    "        sqrt_alphas_cumprod_t = self._get_index_from_list(self.sqrt_alphas_cumprod, t, x_0.shape)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self._get_index_from_list(\n",
    "            self.sqrt_one_minus_alphas_cumprod, t, x_0.shape\n",
    "        )\n",
    "        # mean + variance\n",
    "#         print('sqrt=',sqrt_alphas_cumprod_t.shape, 'x0=', x_0.shape)\n",
    "        return sqrt_alphas_cumprod_t.to(device) * x_0.to(device) \\\n",
    "        + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)\n",
    "\n",
    "\n",
    "    def get_loss(self, model, x_0, t):\n",
    "        x_noisy, noise = self.forward_diffusion_sample(x_0, t, device)\n",
    "        noise_pred = model(x_noisy, t)\n",
    "        return F.l1_loss(noise, noise_pred), x_noisy, noise, noise_pred\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_timestep(self, x, t, model):\n",
    "        \"\"\"\n",
    "        Calls the model to predict the noise in the image and returns \n",
    "        the denoised image. \n",
    "        Applies noise to this image, if we are not in the last step yet.\n",
    "        \n",
    "        x is xt, t is timestamp\n",
    "        return x_{t-1}\n",
    "        \"\"\"\n",
    "        betas_t = self._get_index_from_list(self.betas, t, x.shape)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self._get_index_from_list(\n",
    "            self.sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "        )\n",
    "        sqrt_recip_alphas_t = self._get_index_from_list(self.sqrt_recip_alphas, t, x.shape)\n",
    "\n",
    "        # Call model (current image - noise prediction)\n",
    "        model_mean = sqrt_recip_alphas_t * (\n",
    "            x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "        )\n",
    "        posterior_variance_t = self._get_index_from_list(self.posterior_variance, t, x.shape)\n",
    "\n",
    "        if t == 0:\n",
    "            return model_mean\n",
    "        else:\n",
    "            noise = torch.randn_like(x)\n",
    "            return model_mean + torch.sqrt(posterior_variance_t) * noise \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_plot_image(self, xt=None, num = 5):\n",
    "        '''\n",
    "        分别从纯noise和xt，逐步恢复信息 返回从t=\n",
    "        '''\n",
    "        stepsize = int(self.T / num)\n",
    "        res = []\n",
    "        # Sample noise\n",
    "        if xt is None:\n",
    "            img = torch.randn(xt.shape, device=device)\n",
    "        else:\n",
    "            img = xt\n",
    "        for i in range(0, self.T)[::-1]:\n",
    "            t = torch.full((1,), i, device=device, dtype=torch.long)\n",
    "            img = self.sample_timestep(img, t)\n",
    "            if i % stepsize == 0:\n",
    "                res.append(img.detach().cpu())\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f723937",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Block1D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
    "        super().__init__()\n",
    "        self.time_mlp =  nn.Linear(time_emb_dim, out_ch)\n",
    "        if up:\n",
    "            self.conv1 = nn.Conv1d(2*in_ch, out_ch, 3, padding=1)\n",
    "            self.transform = nn.ConvTranspose1d(out_ch, out_ch, 4, 2, 1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv1d(in_ch, out_ch, 3, padding=1)\n",
    "            self.transform = nn.Conv1d(out_ch, out_ch, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, 3, padding=1)\n",
    "        self.bnorm1 = nn.BatchNorm1d(out_ch)\n",
    "        self.bnorm2 = nn.BatchNorm1d(out_ch)\n",
    "        self.relu  = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, t, ):\n",
    "        # First Conv\n",
    "        h = self.bnorm1(self.relu(self.conv1(x)))\n",
    "        # Time embedding\n",
    "        time_emb = self.relu(self.time_mlp(t))\n",
    "        # Extend last 2 dimensions\n",
    "        time_emb = time_emb[(..., ) + (None, ) * 1]\n",
    "        # Add time channel\n",
    "        h = h + time_emb\n",
    "        # Second Conv\n",
    "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
    "        # Down or Upsample\n",
    "        return self.transform(h)\n",
    "\n",
    "\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        # TODO: Double check the ordering here\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class SimpleUnet1D(nn.Module):\n",
    "    \"\"\"\n",
    "    A simplified variant of the Unet architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self, _image_channels=1):\n",
    "        super().__init__()\n",
    "        image_channels = _image_channels \n",
    "        down_channels = (16,32,64,128)\n",
    "        up_channels = (128,64,32,16)\n",
    "        out_dim = 1 \n",
    "        time_emb_dim = 32\n",
    "\n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "                SinusoidalPositionEmbeddings(time_emb_dim),\n",
    "                nn.Linear(time_emb_dim, time_emb_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        # Initial projection\n",
    "        self.conv0 = nn.Conv1d(image_channels, down_channels[0], 3, padding=1)\n",
    "\n",
    "        # Downsample\n",
    "        self.downs = nn.ModuleList([Block1D(down_channels[i], down_channels[i+1], \\\n",
    "                                    time_emb_dim) \\\n",
    "                    for i in range(len(down_channels)-1)])\n",
    "        # Upsample\n",
    "        self.ups = nn.ModuleList([Block1D(up_channels[i], up_channels[i+1], \\\n",
    "                                        time_emb_dim, up=True) \\\n",
    "                    for i in range(len(up_channels)-1)])\n",
    "\n",
    "        self.output = nn.Conv1d(up_channels[-1], image_channels, out_dim)\n",
    "\n",
    "    def forward(self, x, timestep):\n",
    "        # x shape (batch, channel=1, spectral=200)\n",
    "        # Embedd time\n",
    "        t = self.time_mlp(timestep)\n",
    "        # Initial conv\n",
    "        x = self.conv0(x)\n",
    "        # Unet\n",
    "        residual_inputs = []\n",
    "        for down in self.downs:\n",
    "            x = down(x, t)\n",
    "            residual_inputs.append(x)\n",
    "            # print(\"down\" , x.shape)\n",
    "        for up in self.ups:\n",
    "            residual_x = residual_inputs.pop()\n",
    "            # Add residual x as additional channels\n",
    "            x = torch.cat((x, residual_x), dim=1)           \n",
    "            x = up(x, t)\n",
    "            # print(\"up\",  x.shape)\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "model = SimpleUnet1D()\n",
    "diffusion = Diffusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b34a4c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, epoch_loss=0.7359533051219763, batch_loss=0.564034104347229\n",
      "epoch: 1, epoch_loss=0.4432899054690008, batch_loss=0.39997878670692444\n",
      "epoch: 2, epoch_loss=0.3501453744160293, batch_loss=0.33556509017944336\n",
      "epoch: 3, epoch_loss=0.3296981728374604, batch_loss=0.3205973505973816\n",
      "epoch: 4, epoch_loss=0.31696762806170053, batch_loss=0.32107067108154297\n",
      "epoch: 5, epoch_loss=0.3044800476852127, batch_loss=0.30964457988739014\n",
      "epoch: 6, epoch_loss=0.2987603702017867, batch_loss=0.3031260371208191\n",
      "epoch: 7, epoch_loss=0.29068611843974357, batch_loss=0.3044062554836273\n",
      "epoch: 8, epoch_loss=0.2818117147365166, batch_loss=0.3010668158531189\n",
      "epoch: 9, epoch_loss=0.27191220063800337, batch_loss=0.27067452669143677\n",
      "epoch: 10, epoch_loss=0.2655836780629742, batch_loss=0.269275426864624\n",
      "epoch: 11, epoch_loss=0.26502322037211495, batch_loss=0.2610040009021759\n",
      "epoch: 12, epoch_loss=0.25847614475152725, batch_loss=0.2592470049858093\n",
      "epoch: 13, epoch_loss=0.25149683650552024, batch_loss=0.25618287920951843\n",
      "epoch: 14, epoch_loss=0.25089915783382627, batch_loss=0.24410457909107208\n",
      "epoch: 15, epoch_loss=0.24964366422680415, batch_loss=0.25749295949935913\n",
      "epoch: 16, epoch_loss=0.24693956546210788, batch_loss=0.2524864375591278\n",
      "epoch: 17, epoch_loss=0.24740715404682295, batch_loss=0.24528484046459198\n",
      "epoch: 18, epoch_loss=0.24524506035939692, batch_loss=0.2535979747772217\n",
      "epoch: 19, epoch_loss=0.24369192489474906, batch_loss=0.2391163855791092\n",
      "epoch: 20, epoch_loss=0.2410629941854409, batch_loss=0.23371435701847076\n",
      "epoch: 21, epoch_loss=0.23815975809281562, batch_loss=0.23254509270191193\n",
      "epoch: 22, epoch_loss=0.23801341871515042, batch_loss=0.2387322038412094\n",
      "epoch: 23, epoch_loss=0.23747282870034117, batch_loss=0.22973069548606873\n",
      "epoch: 24, epoch_loss=0.23974302769699504, batch_loss=0.22327598929405212\n",
      "epoch: 25, epoch_loss=0.23307045125791206, batch_loss=0.22474050521850586\n",
      "epoch: 26, epoch_loss=0.23255335174545239, batch_loss=0.22005142271518707\n",
      "epoch: 27, epoch_loss=0.23576615668718087, batch_loss=0.23469890654087067\n",
      "epoch: 28, epoch_loss=0.23379949203852948, batch_loss=0.23031792044639587\n",
      "epoch: 29, epoch_loss=0.2324703419598331, batch_loss=0.2290889173746109\n",
      "epoch: 30, epoch_loss=0.23159621294911212, batch_loss=0.22111667692661285\n",
      "epoch: 31, epoch_loss=0.229910033065272, batch_loss=0.2324524223804474\n",
      "epoch: 32, epoch_loss=0.22778143593091318, batch_loss=0.21325244009494781\n",
      "epoch: 33, epoch_loss=0.2285836425675223, batch_loss=0.23036518692970276\n",
      "epoch: 34, epoch_loss=0.22830696487540156, batch_loss=0.20889484882354736\n",
      "epoch: 35, epoch_loss=0.2276343656372939, batch_loss=0.2193613499403\n",
      "epoch: 36, epoch_loss=0.2267137078099245, batch_loss=0.21810561418533325\n",
      "epoch: 37, epoch_loss=0.22482037760910892, batch_loss=0.21255160868167877\n",
      "epoch: 38, epoch_loss=0.22322751637658947, batch_loss=0.2124408334493637\n",
      "epoch: 39, epoch_loss=0.22152072744689855, batch_loss=0.20284540951251984\n",
      "epoch: 40, epoch_loss=0.2179903797183394, batch_loss=0.2187805026769638\n",
      "epoch: 41, epoch_loss=0.21995337355788908, batch_loss=0.21696804463863373\n",
      "epoch: 42, epoch_loss=0.21814276382628292, batch_loss=0.20607788860797882\n",
      "epoch: 43, epoch_loss=0.21352792502087448, batch_loss=0.21161611378192902\n",
      "epoch: 44, epoch_loss=0.21418212011934887, batch_loss=0.21326187252998352\n",
      "epoch: 45, epoch_loss=0.21685049575659382, batch_loss=0.20167621970176697\n",
      "epoch: 46, epoch_loss=0.212649147659363, batch_loss=0.20742091536521912\n",
      "epoch: 47, epoch_loss=0.2115154246441958, batch_loss=0.20117101073265076\n",
      "epoch: 48, epoch_loss=0.21024196141965323, batch_loss=0.1953759789466858\n",
      "epoch: 49, epoch_loss=0.2095546901211869, batch_loss=0.2078496813774109\n",
      "epoch: 50, epoch_loss=0.21157936516825848, batch_loss=0.19580768048763275\n",
      "epoch: 51, epoch_loss=0.2091885265966658, batch_loss=0.20326849818229675\n",
      "epoch: 52, epoch_loss=0.20993700360996687, batch_loss=0.20166876912117004\n",
      "epoch: 53, epoch_loss=0.2108619066254279, batch_loss=0.19849109649658203\n",
      "epoch: 54, epoch_loss=0.21011296688659864, batch_loss=0.19659189879894257\n",
      "epoch: 55, epoch_loss=0.21130886088157522, batch_loss=0.2047431617975235\n",
      "epoch: 56, epoch_loss=0.21413662510663803, batch_loss=0.19524918496608734\n",
      "epoch: 57, epoch_loss=0.21048042237049902, batch_loss=0.19516582787036896\n",
      "epoch: 58, epoch_loss=0.20434181020390266, batch_loss=0.19594664871692657\n",
      "epoch: 59, epoch_loss=0.20577178075891897, batch_loss=0.19243685901165009\n",
      "epoch: 60, epoch_loss=0.20221142637035083, batch_loss=0.1954595446586609\n",
      "epoch: 61, epoch_loss=0.2025937843485763, batch_loss=0.20627914369106293\n",
      "epoch: 62, epoch_loss=0.2030456920802664, batch_loss=0.19994495809078217\n",
      "epoch: 63, epoch_loss=0.20352552498634308, batch_loss=0.18750445544719696\n",
      "epoch: 64, epoch_loss=0.20405677633818492, batch_loss=0.19446790218353271\n",
      "epoch: 65, epoch_loss=0.20321283618845357, batch_loss=0.19404971599578857\n",
      "epoch: 66, epoch_loss=0.2020731416163915, batch_loss=0.19564159214496613\n",
      "epoch: 67, epoch_loss=0.19809781744349725, batch_loss=0.18623296916484833\n",
      "epoch: 68, epoch_loss=0.2001662831570107, batch_loss=0.1915808618068695\n",
      "epoch: 69, epoch_loss=0.19953025794341078, batch_loss=0.18981057405471802\n",
      "epoch: 70, epoch_loss=0.19887933775233316, batch_loss=0.19077752530574799\n",
      "epoch: 71, epoch_loss=0.20185277030385773, batch_loss=0.21326276659965515\n",
      "epoch: 72, epoch_loss=0.34429559652076747, batch_loss=0.6186201572418213\n",
      "epoch: 73, epoch_loss=0.7416232848394215, batch_loss=0.42026084661483765\n",
      "epoch: 74, epoch_loss=0.5479193535556974, batch_loss=0.4270721971988678\n",
      "epoch: 75, epoch_loss=0.38708269706662574, batch_loss=0.28229713439941406\n",
      "epoch: 76, epoch_loss=0.2646829304053015, batch_loss=0.22678355872631073\n",
      "epoch: 77, epoch_loss=0.27832770421728936, batch_loss=0.28268155455589294\n",
      "epoch: 78, epoch_loss=0.30207385843347284, batch_loss=0.25556063652038574\n",
      "epoch: 79, epoch_loss=0.29342215893951806, batch_loss=0.25107118487358093\n",
      "epoch: 80, epoch_loss=0.23196543469369482, batch_loss=0.2412308007478714\n",
      "epoch: 81, epoch_loss=0.27680228826690656, batch_loss=0.21996742486953735\n",
      "epoch: 82, epoch_loss=0.26416193663365206, batch_loss=0.22628630697727203\n",
      "epoch: 83, epoch_loss=0.2194448577826145, batch_loss=0.2048557847738266\n",
      "epoch: 84, epoch_loss=0.20602978548453624, batch_loss=0.2018551230430603\n",
      "epoch: 85, epoch_loss=0.20405885612355118, batch_loss=0.19147011637687683\n",
      "epoch: 86, epoch_loss=0.19720154635971424, batch_loss=0.1884550154209137\n",
      "epoch: 87, epoch_loss=0.1966657173045325, batch_loss=0.18949244916439056\n",
      "epoch: 88, epoch_loss=0.19502137239211806, batch_loss=0.1857088953256607\n",
      "epoch: 89, epoch_loss=0.1930227836821224, batch_loss=0.17850573360919952\n",
      "epoch: 90, epoch_loss=0.19248062101399857, batch_loss=0.18059669435024261\n",
      "epoch: 91, epoch_loss=0.19205711641861625, batch_loss=0.18563851714134216\n",
      "epoch: 92, epoch_loss=0.19224542230403097, batch_loss=0.18612107634544373\n",
      "epoch: 93, epoch_loss=0.19354581308421567, batch_loss=0.17688357830047607\n",
      "epoch: 94, epoch_loss=0.19245706334125415, batch_loss=0.18689927458763123\n",
      "epoch: 95, epoch_loss=0.19236443763893368, batch_loss=0.18174229562282562\n",
      "epoch: 96, epoch_loss=0.18862786943152743, batch_loss=0.180455282330513\n",
      "epoch: 97, epoch_loss=0.18922721650526725, batch_loss=0.17993231117725372\n",
      "epoch: 98, epoch_loss=0.19188465654779133, batch_loss=0.18449711799621582\n",
      "epoch: 99, epoch_loss=0.19002795425734254, batch_loss=0.1831519454717636\n",
      "epoch: 100, epoch_loss=0.19227704316980065, batch_loss=0.18442536890506744\n",
      "epoch: 101, epoch_loss=0.19157090864340276, batch_loss=0.18934780359268188\n",
      "epoch: 102, epoch_loss=0.19346292595092238, batch_loss=0.18115940690040588\n",
      "epoch: 103, epoch_loss=0.1928122404107866, batch_loss=0.18116427958011627\n",
      "epoch: 104, epoch_loss=0.18922717739157954, batch_loss=0.19147910177707672\n",
      "epoch: 105, epoch_loss=0.18913872923210318, batch_loss=0.1839478611946106\n",
      "epoch: 106, epoch_loss=0.19001706200533333, batch_loss=0.18517471849918365\n",
      "epoch: 107, epoch_loss=0.19052216487818183, batch_loss=0.17418812215328217\n",
      "epoch: 108, epoch_loss=0.18685071526327826, batch_loss=0.18400397896766663\n",
      "epoch: 109, epoch_loss=0.18696596539190635, batch_loss=0.18226124346256256\n",
      "epoch: 110, epoch_loss=0.1877898553690644, batch_loss=0.17814964056015015\n",
      "epoch: 111, epoch_loss=0.18484544264646546, batch_loss=0.174599751830101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112, epoch_loss=0.18485075427434108, batch_loss=0.19096890091896057\n",
      "epoch: 113, epoch_loss=0.1904562009607002, batch_loss=0.18054626882076263\n",
      "epoch: 114, epoch_loss=0.1869781337091954, batch_loss=0.18500258028507233\n",
      "epoch: 115, epoch_loss=0.18692127917524468, batch_loss=0.18551164865493774\n",
      "epoch: 116, epoch_loss=0.18900034870460683, batch_loss=0.18624234199523926\n",
      "epoch: 117, epoch_loss=0.18709418645015652, batch_loss=0.19142533838748932\n",
      "epoch: 118, epoch_loss=0.18851656470159855, batch_loss=0.18392033874988556\n",
      "epoch: 119, epoch_loss=0.1881585103138732, batch_loss=0.1773546040058136\n",
      "epoch: 120, epoch_loss=0.1888755955934241, batch_loss=0.18048995733261108\n",
      "epoch: 121, epoch_loss=0.18470919768818778, batch_loss=0.18197914958000183\n",
      "epoch: 122, epoch_loss=0.18706170998628868, batch_loss=0.17157012224197388\n",
      "epoch: 123, epoch_loss=0.18598840943131237, batch_loss=0.1809931993484497\n",
      "epoch: 124, epoch_loss=0.18652278182055806, batch_loss=0.18483227491378784\n",
      "epoch: 125, epoch_loss=0.18760894839318557, batch_loss=0.17840871214866638\n",
      "epoch: 126, epoch_loss=0.18806949360192035, batch_loss=0.18135997653007507\n",
      "epoch: 127, epoch_loss=0.18779143665619327, batch_loss=0.17487286031246185\n",
      "epoch: 128, epoch_loss=0.18675634924495121, batch_loss=0.178017258644104\n",
      "epoch: 129, epoch_loss=0.1892459651476988, batch_loss=0.1821504533290863\n",
      "epoch: 130, epoch_loss=0.18894925648689836, batch_loss=0.17943082749843597\n",
      "epoch: 131, epoch_loss=0.19004289212961117, batch_loss=0.1880633383989334\n",
      "epoch: 132, epoch_loss=0.18683654959363405, batch_loss=0.1866087019443512\n",
      "epoch: 133, epoch_loss=0.18797169438085998, batch_loss=0.18379329144954681\n",
      "epoch: 134, epoch_loss=0.19013509241494214, batch_loss=0.18457728624343872\n",
      "epoch: 135, epoch_loss=0.18690372087725846, batch_loss=0.1813901662826538\n",
      "epoch: 136, epoch_loss=0.18695372764831775, batch_loss=0.17513339221477509\n",
      "epoch: 137, epoch_loss=0.18637964830032852, batch_loss=0.1784030646085739\n",
      "epoch: 138, epoch_loss=0.18595719447388234, batch_loss=0.16942499577999115\n",
      "epoch: 139, epoch_loss=0.18540560876642764, batch_loss=0.1723787933588028\n",
      "epoch: 140, epoch_loss=0.1840608274192504, batch_loss=0.18152357637882233\n",
      "epoch: 141, epoch_loss=0.1850168343878813, batch_loss=0.18518413603305817\n",
      "epoch: 142, epoch_loss=0.18568981254285072, batch_loss=0.18044990301132202\n",
      "epoch: 143, epoch_loss=0.18487389385558478, batch_loss=0.17802362143993378\n",
      "epoch: 144, epoch_loss=0.18457157320060572, batch_loss=0.18678312003612518\n",
      "epoch: 145, epoch_loss=0.1830083420777009, batch_loss=0.17557881772518158\n",
      "epoch: 146, epoch_loss=0.18409003299779472, batch_loss=0.1774907261133194\n",
      "epoch: 147, epoch_loss=0.1842809955260133, batch_loss=0.17690104246139526\n",
      "epoch: 148, epoch_loss=0.18368025738900964, batch_loss=0.18024516105651855\n",
      "epoch: 149, epoch_loss=0.19062473431070126, batch_loss=0.17587044835090637\n",
      "epoch: 150, epoch_loss=0.19305508284095352, batch_loss=0.17706023156642914\n",
      "epoch: 151, epoch_loss=0.19194776996420906, batch_loss=0.1780683696269989\n",
      "epoch: 152, epoch_loss=0.19366335731482534, batch_loss=0.17571398615837097\n",
      "epoch: 153, epoch_loss=0.192142459422031, batch_loss=0.17822211980819702\n",
      "epoch: 154, epoch_loss=0.1918110319571603, batch_loss=0.17283551394939423\n",
      "epoch: 155, epoch_loss=0.18731554234070386, batch_loss=0.17041701078414917\n",
      "epoch: 156, epoch_loss=0.18924265845564683, batch_loss=0.17859433591365814\n",
      "epoch: 157, epoch_loss=0.18424135028678088, batch_loss=0.17408651113510132\n",
      "epoch: 158, epoch_loss=0.1845280262590447, batch_loss=0.17477741837501526\n",
      "epoch: 159, epoch_loss=0.18347586397041749, batch_loss=0.17681121826171875\n",
      "epoch: 160, epoch_loss=0.1832778297572017, batch_loss=0.18709160387516022\n",
      "epoch: 161, epoch_loss=0.18453798696416454, batch_loss=0.1731097251176834\n",
      "epoch: 162, epoch_loss=0.1833966329782386, batch_loss=0.17123647034168243\n",
      "epoch: 163, epoch_loss=0.1861359366841889, batch_loss=0.1777775138616562\n",
      "epoch: 164, epoch_loss=0.185882386743101, batch_loss=0.17277052998542786\n",
      "epoch: 165, epoch_loss=0.18522948914915147, batch_loss=0.16971255838871002\n",
      "epoch: 166, epoch_loss=0.19305364454402085, batch_loss=0.1814846694469452\n",
      "epoch: 167, epoch_loss=0.18552946866267359, batch_loss=0.17926691472530365\n",
      "epoch: 168, epoch_loss=0.1883753213757709, batch_loss=0.181288480758667\n",
      "epoch: 169, epoch_loss=0.18926047654058364, batch_loss=0.18616844713687897\n",
      "epoch: 170, epoch_loss=0.1879838797347299, batch_loss=0.17526276409626007\n",
      "epoch: 171, epoch_loss=0.18838194663190105, batch_loss=0.17998380959033966\n",
      "epoch: 172, epoch_loss=0.18873206461227182, batch_loss=0.18306243419647217\n",
      "epoch: 173, epoch_loss=0.1920798811107413, batch_loss=0.18196731805801392\n",
      "epoch: 174, epoch_loss=0.19679124057009445, batch_loss=0.18415270745754242\n",
      "epoch: 175, epoch_loss=0.20071629100761573, batch_loss=0.18042124807834625\n",
      "epoch: 176, epoch_loss=0.1905631610301105, batch_loss=0.17270934581756592\n",
      "epoch: 177, epoch_loss=0.1858332248668183, batch_loss=0.1728711575269699\n",
      "epoch: 178, epoch_loss=0.18628445327069332, batch_loss=0.1821284294128418\n",
      "epoch: 179, epoch_loss=0.18338598077206492, batch_loss=0.18568764626979828\n",
      "epoch: 180, epoch_loss=0.18561909930884626, batch_loss=0.17821362614631653\n",
      "epoch: 181, epoch_loss=0.18098961733467656, batch_loss=0.17230695486068726\n",
      "epoch: 182, epoch_loss=0.1808402097905575, batch_loss=0.16829952597618103\n",
      "epoch: 183, epoch_loss=0.1840227737345962, batch_loss=0.17749111354351044\n",
      "epoch: 184, epoch_loss=0.182270565916752, batch_loss=0.17302845418453217\n",
      "epoch: 185, epoch_loss=0.18384244417180345, batch_loss=0.1785811483860016\n",
      "epoch: 186, epoch_loss=0.18199605009572825, batch_loss=0.17727325856685638\n",
      "epoch: 187, epoch_loss=0.18379176952963636, batch_loss=0.17304183542728424\n",
      "epoch: 188, epoch_loss=0.18843455047230376, batch_loss=0.17385511100292206\n",
      "epoch: 189, epoch_loss=0.1848536767758314, batch_loss=0.17488840222358704\n",
      "epoch: 190, epoch_loss=0.1835535214687216, batch_loss=0.17740947008132935\n",
      "epoch: 191, epoch_loss=0.18271515388834633, batch_loss=0.1692737638950348\n",
      "epoch: 192, epoch_loss=0.18113105878960364, batch_loss=0.17187896370887756\n",
      "epoch: 193, epoch_loss=0.18288304182351983, batch_loss=0.18013471364974976\n",
      "epoch: 194, epoch_loss=0.18278176189957276, batch_loss=0.1771705597639084\n",
      "epoch: 195, epoch_loss=0.1826381423066544, batch_loss=0.1785990446805954\n",
      "epoch: 196, epoch_loss=0.18089280652730558, batch_loss=0.18337948620319366\n",
      "epoch: 197, epoch_loss=0.18197710910960413, batch_loss=0.17833435535430908\n",
      "epoch: 198, epoch_loss=0.18576568258928486, batch_loss=0.17490676045417786\n",
      "epoch: 199, epoch_loss=0.17826376662739107, batch_loss=0.16915859282016754\n",
      "epoch: 200, epoch_loss=0.17562960275500905, batch_loss=0.1739361435174942\n",
      "epoch: 201, epoch_loss=0.1775808540606754, batch_loss=0.1824328601360321\n",
      "epoch: 202, epoch_loss=0.17654652011947314, batch_loss=0.17293128371238708\n",
      "epoch: 203, epoch_loss=0.1772811956985385, batch_loss=0.16608233749866486\n",
      "epoch: 204, epoch_loss=0.17522255776328224, batch_loss=0.1691136658191681\n",
      "epoch: 205, epoch_loss=0.17711404624648666, batch_loss=0.1760709285736084\n",
      "epoch: 206, epoch_loss=0.17892543453807355, batch_loss=0.17624977231025696\n",
      "epoch: 207, epoch_loss=0.1801617601248087, batch_loss=0.17523233592510223\n",
      "epoch: 208, epoch_loss=0.17947361537378267, batch_loss=0.17965377867221832\n",
      "epoch: 209, epoch_loss=0.1808915836164699, batch_loss=0.1692620813846588\n",
      "epoch: 210, epoch_loss=0.1806935788405778, batch_loss=0.1807645857334137\n",
      "epoch: 211, epoch_loss=0.17660899179443876, batch_loss=0.17124512791633606\n",
      "epoch: 212, epoch_loss=0.17598746966238396, batch_loss=0.16759556531906128\n",
      "epoch: 213, epoch_loss=0.17855352870490973, batch_loss=0.16962608695030212\n",
      "epoch: 214, epoch_loss=0.17898904010245972, batch_loss=0.17112617194652557\n",
      "epoch: 215, epoch_loss=0.17932227671571635, batch_loss=0.17621098458766937\n",
      "epoch: 216, epoch_loss=0.18047853569992942, batch_loss=0.17103584110736847\n",
      "epoch: 217, epoch_loss=0.1846609058398554, batch_loss=0.17448081076145172\n",
      "epoch: 218, epoch_loss=0.18107395053122471, batch_loss=0.17424608767032623\n",
      "epoch: 219, epoch_loss=0.18078229927988312, batch_loss=0.17169642448425293\n",
      "epoch: 220, epoch_loss=0.177568154575992, batch_loss=0.16448873281478882\n",
      "epoch: 221, epoch_loss=0.1767509951751666, batch_loss=0.170389786362648\n",
      "epoch: 222, epoch_loss=0.18000223024917697, batch_loss=0.1667177826166153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 223, epoch_loss=0.18392411589409877, batch_loss=0.16913942992687225\n",
      "epoch: 224, epoch_loss=0.17938327929423623, batch_loss=0.18311633169651031\n",
      "epoch: 225, epoch_loss=0.1811715045135455, batch_loss=0.17763866484165192\n",
      "epoch: 226, epoch_loss=0.17999352505105004, batch_loss=0.1816737800836563\n",
      "epoch: 227, epoch_loss=0.18333246580627388, batch_loss=0.16880565881729126\n",
      "epoch: 228, epoch_loss=0.18369420453356788, batch_loss=0.17383702099323273\n",
      "epoch: 229, epoch_loss=0.18049189151183886, batch_loss=0.16954274475574493\n",
      "epoch: 230, epoch_loss=0.1800179308475694, batch_loss=0.16778185963630676\n",
      "epoch: 231, epoch_loss=0.1789738156856453, batch_loss=0.17939336597919464\n",
      "epoch: 232, epoch_loss=0.1819982147918445, batch_loss=0.19267849624156952\n",
      "epoch: 233, epoch_loss=0.18421618525111577, batch_loss=0.17383646965026855\n",
      "epoch: 234, epoch_loss=0.17960262229057045, batch_loss=0.1666814535856247\n",
      "epoch: 235, epoch_loss=0.17632459425614366, batch_loss=0.16910946369171143\n",
      "epoch: 236, epoch_loss=0.17378254703548376, batch_loss=0.16204504668712616\n",
      "epoch: 237, epoch_loss=0.1747736413080542, batch_loss=0.1676039844751358\n",
      "epoch: 238, epoch_loss=0.17617233523574086, batch_loss=0.16942071914672852\n",
      "epoch: 239, epoch_loss=0.17710204030047133, batch_loss=0.1647595763206482\n",
      "epoch: 240, epoch_loss=0.17515841593498566, batch_loss=0.16868102550506592\n",
      "epoch: 241, epoch_loss=0.17714403749221003, batch_loss=0.1711598038673401\n",
      "epoch: 242, epoch_loss=0.17636991696678075, batch_loss=0.17619435489177704\n",
      "epoch: 243, epoch_loss=0.17828572853708663, batch_loss=0.17437002062797546\n",
      "epoch: 244, epoch_loss=0.17877280092196857, batch_loss=0.16814203560352325\n",
      "epoch: 245, epoch_loss=0.17748187834244136, batch_loss=0.17034369707107544\n",
      "epoch: 246, epoch_loss=0.17670515117903243, batch_loss=0.16646449267864227\n",
      "epoch: 247, epoch_loss=0.17392489969659503, batch_loss=0.16228199005126953\n",
      "epoch: 248, epoch_loss=0.1748044387027001, batch_loss=0.17467206716537476\n",
      "epoch: 249, epoch_loss=0.1719817106888212, batch_loss=0.16813847422599792\n",
      "epoch: 250, epoch_loss=0.17370635898728434, batch_loss=0.17095822095870972\n",
      "epoch: 251, epoch_loss=0.1743354910023856, batch_loss=0.16668736934661865\n",
      "epoch: 252, epoch_loss=0.17520867642480326, batch_loss=0.17515729367733002\n",
      "epoch: 253, epoch_loss=0.1758120601377079, batch_loss=0.16663967072963715\n",
      "epoch: 254, epoch_loss=0.17524120264685536, batch_loss=0.17435352504253387\n",
      "epoch: 255, epoch_loss=0.17253062316622944, batch_loss=0.1646474152803421\n",
      "epoch: 256, epoch_loss=0.17289632060227297, batch_loss=0.17594005167484283\n",
      "epoch: 257, epoch_loss=0.17509008089016223, batch_loss=0.17278935015201569\n",
      "epoch: 258, epoch_loss=0.17720087079882763, batch_loss=0.1705167591571808\n",
      "epoch: 259, epoch_loss=0.17744115485022383, batch_loss=0.18109852075576782\n",
      "epoch: 260, epoch_loss=0.1827569076854749, batch_loss=0.16969306766986847\n",
      "epoch: 261, epoch_loss=0.17933615782669127, batch_loss=0.17857827246189117\n",
      "epoch: 262, epoch_loss=0.17852976573775128, batch_loss=0.1788521707057953\n",
      "epoch: 263, epoch_loss=0.1794332066174778, batch_loss=0.16984954476356506\n",
      "epoch: 264, epoch_loss=0.1775036109698655, batch_loss=0.17288833856582642\n",
      "epoch: 265, epoch_loss=0.17668378494157236, batch_loss=0.174467533826828\n",
      "epoch: 266, epoch_loss=0.1762868962000156, batch_loss=0.1694246083498001\n",
      "epoch: 267, epoch_loss=0.17519617505646207, batch_loss=0.17791956663131714\n",
      "epoch: 268, epoch_loss=0.17576447548183052, batch_loss=0.16969992220401764\n",
      "epoch: 269, epoch_loss=0.1763415285062563, batch_loss=0.1684020608663559\n",
      "epoch: 270, epoch_loss=0.17778619753123748, batch_loss=0.16882716119289398\n",
      "epoch: 271, epoch_loss=0.17709945022705478, batch_loss=0.17712342739105225\n",
      "epoch: 272, epoch_loss=0.1770551980094592, batch_loss=0.17351269721984863\n",
      "epoch: 273, epoch_loss=0.1783640372427125, batch_loss=0.19426846504211426\n",
      "epoch: 274, epoch_loss=0.38218071311038965, batch_loss=0.6663838624954224\n",
      "epoch: 275, epoch_loss=1.2946035692963958, batch_loss=0.42099061608314514\n",
      "epoch: 276, epoch_loss=0.8497613165891695, batch_loss=0.7027372717857361\n",
      "epoch: 277, epoch_loss=0.7088753469407062, batch_loss=0.540431559085846\n",
      "epoch: 278, epoch_loss=0.4284887150550144, batch_loss=0.3943319320678711\n",
      "epoch: 279, epoch_loss=0.2905781369387891, batch_loss=0.2531103193759918\n",
      "epoch: 280, epoch_loss=0.20864713787111175, batch_loss=0.1925078183412552\n",
      "epoch: 281, epoch_loss=0.18513895714750755, batch_loss=0.17017307877540588\n",
      "epoch: 282, epoch_loss=0.17665764932683475, batch_loss=0.16634425520896912\n",
      "epoch: 283, epoch_loss=0.17657702684331592, batch_loss=0.16930179297924042\n",
      "epoch: 284, epoch_loss=0.17638500137008753, batch_loss=0.16810475289821625\n",
      "epoch: 285, epoch_loss=0.17507420764808565, batch_loss=0.16356834769248962\n",
      "epoch: 286, epoch_loss=0.1760873204356283, batch_loss=0.16832859814167023\n",
      "epoch: 287, epoch_loss=0.1773547060488237, batch_loss=0.1669597178697586\n",
      "epoch: 288, epoch_loss=0.1766015508526429, batch_loss=0.16339895129203796\n",
      "epoch: 289, epoch_loss=0.1745915921512597, batch_loss=0.16716031730175018\n",
      "epoch: 290, epoch_loss=0.17366180354151234, batch_loss=0.16488027572631836\n",
      "epoch: 291, epoch_loss=0.17321228744300451, batch_loss=0.16904836893081665\n",
      "epoch: 292, epoch_loss=0.17306359444872235, batch_loss=0.16629520058631897\n",
      "epoch: 293, epoch_loss=0.1748710315873875, batch_loss=0.1711343228816986\n",
      "epoch: 294, epoch_loss=0.17413446663676205, batch_loss=0.16782838106155396\n",
      "epoch: 295, epoch_loss=0.17396273631828435, batch_loss=0.16789808869361877\n",
      "epoch: 296, epoch_loss=0.17382600600172307, batch_loss=0.16686144471168518\n",
      "epoch: 297, epoch_loss=0.1720928690854491, batch_loss=0.17308233678340912\n",
      "epoch: 298, epoch_loss=0.17398336412436047, batch_loss=0.1662716120481491\n",
      "epoch: 299, epoch_loss=0.1739582022255581, batch_loss=0.17012633383274078\n",
      "epoch: 300, epoch_loss=0.17436432636733853, batch_loss=0.16721037030220032\n",
      "epoch: 301, epoch_loss=0.17309675991322565, batch_loss=0.16977813839912415\n",
      "epoch: 302, epoch_loss=0.17313023257978463, batch_loss=0.1676069051027298\n",
      "epoch: 303, epoch_loss=0.17838316034193413, batch_loss=0.17374613881111145\n",
      "epoch: 304, epoch_loss=0.1774762424695506, batch_loss=0.16946278512477875\n",
      "epoch: 305, epoch_loss=0.17675934942312954, batch_loss=0.17261122167110443\n",
      "epoch: 306, epoch_loss=0.17647172382059337, batch_loss=0.16246287524700165\n",
      "epoch: 307, epoch_loss=0.17510178615803101, batch_loss=0.17116712033748627\n",
      "epoch: 308, epoch_loss=0.17535430182883346, batch_loss=0.1674395501613617\n",
      "epoch: 309, epoch_loss=0.1761767394690111, batch_loss=0.17112025618553162\n",
      "epoch: 310, epoch_loss=0.17775429224854558, batch_loss=0.17372402548789978\n",
      "epoch: 311, epoch_loss=0.17647299081406043, batch_loss=0.1641370803117752\n",
      "epoch: 312, epoch_loss=0.17563838979718802, batch_loss=0.1756054162979126\n",
      "epoch: 313, epoch_loss=0.17737937555656139, batch_loss=0.16489560902118683\n",
      "epoch: 314, epoch_loss=0.17827914249528462, batch_loss=0.16514568030834198\n",
      "epoch: 315, epoch_loss=0.1773163938869619, batch_loss=0.17272008955478668\n",
      "epoch: 316, epoch_loss=0.17634550790015638, batch_loss=0.1736782193183899\n",
      "epoch: 317, epoch_loss=0.17925638992140042, batch_loss=0.1664666086435318\n",
      "epoch: 318, epoch_loss=0.181861177614838, batch_loss=0.17246094346046448\n",
      "epoch: 319, epoch_loss=0.1807819669730031, batch_loss=0.17309866845607758\n",
      "epoch: 320, epoch_loss=0.1786970517227114, batch_loss=0.17239651083946228\n",
      "epoch: 321, epoch_loss=0.17774848102672772, batch_loss=0.16607555747032166\n",
      "epoch: 322, epoch_loss=0.1777472625950996, batch_loss=0.17049257457256317\n",
      "epoch: 323, epoch_loss=0.17706727234276806, batch_loss=0.16506171226501465\n",
      "epoch: 324, epoch_loss=0.17845102024843804, batch_loss=0.1673170030117035\n",
      "epoch: 325, epoch_loss=0.1768447296826366, batch_loss=0.16733282804489136\n",
      "epoch: 326, epoch_loss=0.17690252723790237, batch_loss=0.16700080037117004\n",
      "epoch: 327, epoch_loss=0.1725917666278753, batch_loss=0.16677242517471313\n",
      "epoch: 328, epoch_loss=0.17338607109330073, batch_loss=0.16936002671718597\n",
      "epoch: 329, epoch_loss=0.17157303954914266, batch_loss=0.16466586291790009\n",
      "epoch: 330, epoch_loss=0.17292209651254728, batch_loss=0.16654132306575775\n",
      "epoch: 331, epoch_loss=0.17109568527847635, batch_loss=0.1670091152191162\n",
      "epoch: 332, epoch_loss=0.1717951700321701, batch_loss=0.17000174522399902\n",
      "epoch: 333, epoch_loss=0.17105150465307564, batch_loss=0.16484734416007996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 334, epoch_loss=0.17152352871353363, batch_loss=0.16658537089824677\n",
      "epoch: 335, epoch_loss=0.1744082161015194, batch_loss=0.1692628711462021\n",
      "epoch: 336, epoch_loss=0.1728023162594023, batch_loss=0.16620931029319763\n",
      "epoch: 337, epoch_loss=0.1719625813470584, batch_loss=0.17115360498428345\n",
      "epoch: 338, epoch_loss=0.1737906539822872, batch_loss=0.1643107533454895\n",
      "epoch: 339, epoch_loss=0.17288045240426603, batch_loss=0.171861931681633\n",
      "epoch: 340, epoch_loss=0.17385188559927356, batch_loss=0.17681889235973358\n",
      "epoch: 341, epoch_loss=0.17655675980834984, batch_loss=0.17113061249256134\n",
      "epoch: 342, epoch_loss=0.1747833845958415, batch_loss=0.16540104150772095\n",
      "epoch: 343, epoch_loss=0.1736808116895265, batch_loss=0.16776660084724426\n",
      "epoch: 344, epoch_loss=0.17325284831163856, batch_loss=0.168950617313385\n",
      "epoch: 345, epoch_loss=0.17125540688545327, batch_loss=0.1593989133834839\n",
      "epoch: 346, epoch_loss=0.1693572160392539, batch_loss=0.1643679440021515\n",
      "epoch: 347, epoch_loss=0.17014331602100527, batch_loss=0.1684703677892685\n",
      "epoch: 348, epoch_loss=0.1726868735404417, batch_loss=0.1691032201051712\n",
      "epoch: 349, epoch_loss=0.17536335014843346, batch_loss=0.17426791787147522\n",
      "epoch: 350, epoch_loss=0.17456292957102926, batch_loss=0.15775743126869202\n",
      "epoch: 351, epoch_loss=0.173744336558012, batch_loss=0.16654014587402344\n",
      "epoch: 352, epoch_loss=0.17007085109720899, batch_loss=0.16930797696113586\n",
      "epoch: 353, epoch_loss=0.17131051956473292, batch_loss=0.16026078164577484\n",
      "epoch: 354, epoch_loss=0.17041719714115405, batch_loss=0.1591150015592575\n",
      "epoch: 355, epoch_loss=0.17215070945045752, batch_loss=0.16809475421905518\n",
      "epoch: 356, epoch_loss=0.17119176216698145, batch_loss=0.16943517327308655\n",
      "epoch: 357, epoch_loss=0.1679819377828013, batch_loss=0.16314645111560822\n",
      "epoch: 358, epoch_loss=0.1672413235215313, batch_loss=0.15644842386245728\n",
      "epoch: 359, epoch_loss=0.16889995305560856, batch_loss=0.16088496148586273\n",
      "epoch: 360, epoch_loss=0.16923229725834305, batch_loss=0.16837412118911743\n",
      "epoch: 361, epoch_loss=0.1703919372065314, batch_loss=0.16185694932937622\n",
      "epoch: 362, epoch_loss=0.17003720727956254, batch_loss=0.17151997983455658\n",
      "epoch: 363, epoch_loss=0.16897682076685494, batch_loss=0.1629333794116974\n",
      "epoch: 364, epoch_loss=0.17059462833631336, batch_loss=0.16396033763885498\n",
      "epoch: 365, epoch_loss=0.16791680229617356, batch_loss=0.16054467856884003\n",
      "epoch: 366, epoch_loss=0.16973835063887832, batch_loss=0.1671123206615448\n",
      "epoch: 367, epoch_loss=0.16873908562906856, batch_loss=0.15708722174167633\n",
      "epoch: 368, epoch_loss=0.16867823333575807, batch_loss=0.1668461263179779\n",
      "epoch: 369, epoch_loss=0.1685523629698827, batch_loss=0.1566721796989441\n",
      "epoch: 370, epoch_loss=0.17007977004354546, batch_loss=0.17198051512241364\n",
      "epoch: 371, epoch_loss=0.1680249985602466, batch_loss=0.16832181811332703\n",
      "epoch: 372, epoch_loss=0.16795721496965882, batch_loss=0.16791023313999176\n",
      "epoch: 373, epoch_loss=0.17098139963025286, batch_loss=0.16786658763885498\n",
      "epoch: 374, epoch_loss=0.17047511205024016, batch_loss=0.16605018079280853\n",
      "epoch: 375, epoch_loss=0.17085733361604238, batch_loss=0.16289760172367096\n",
      "epoch: 376, epoch_loss=0.1712053221960272, batch_loss=0.16031910479068756\n",
      "epoch: 377, epoch_loss=0.17115290334902253, batch_loss=0.16699036955833435\n",
      "epoch: 378, epoch_loss=0.16926375178179476, batch_loss=0.15654301643371582\n",
      "epoch: 379, epoch_loss=0.17155755919806315, batch_loss=0.16278843581676483\n",
      "epoch: 380, epoch_loss=0.1681630502565012, batch_loss=0.15707708895206451\n",
      "epoch: 381, epoch_loss=0.16648200692163778, batch_loss=0.1616717427968979\n",
      "epoch: 382, epoch_loss=0.17032964840442757, batch_loss=0.1667190045118332\n",
      "epoch: 383, epoch_loss=0.17015950409750877, batch_loss=0.17585930228233337\n",
      "epoch: 384, epoch_loss=0.1728954455947479, batch_loss=0.16610892117023468\n",
      "epoch: 385, epoch_loss=0.1718259600368323, batch_loss=0.16639113426208496\n",
      "epoch: 386, epoch_loss=0.17186509220126692, batch_loss=0.16973742842674255\n",
      "epoch: 387, epoch_loss=0.17153619545818652, batch_loss=0.16968241333961487\n",
      "epoch: 388, epoch_loss=0.1721987895669325, batch_loss=0.16288356482982635\n",
      "epoch: 389, epoch_loss=0.1738025476554061, batch_loss=0.1690487116575241\n",
      "epoch: 390, epoch_loss=0.17212287517988725, batch_loss=0.1704179346561432\n",
      "epoch: 391, epoch_loss=0.17213143932762667, batch_loss=0.16398288309574127\n",
      "epoch: 392, epoch_loss=0.17273229236764376, batch_loss=0.1645747572183609\n",
      "epoch: 393, epoch_loss=0.17418192439498856, batch_loss=0.16193607449531555\n",
      "epoch: 394, epoch_loss=0.17216977539867623, batch_loss=0.16631311178207397\n",
      "epoch: 395, epoch_loss=0.1698901903990758, batch_loss=0.16368956863880157\n",
      "epoch: 396, epoch_loss=0.17051699157560624, batch_loss=0.16440272331237793\n",
      "epoch: 397, epoch_loss=0.16977975237100218, batch_loss=0.16434040665626526\n",
      "epoch: 398, epoch_loss=0.1684013932319657, batch_loss=0.16012905538082123\n",
      "epoch: 399, epoch_loss=0.16843884193301908, batch_loss=0.16136471927165985\n",
      "epoch: 400, epoch_loss=0.16933177160663923, batch_loss=0.16028587520122528\n",
      "epoch: 401, epoch_loss=0.16854606994054547, batch_loss=0.16037283837795258\n",
      "epoch: 402, epoch_loss=0.1696983993166834, batch_loss=0.16457626223564148\n",
      "epoch: 403, epoch_loss=0.17033648014919087, batch_loss=0.15964490175247192\n",
      "epoch: 404, epoch_loss=0.17060802210596313, batch_loss=0.16636045277118683\n",
      "epoch: 405, epoch_loss=0.17037489237952602, batch_loss=0.1685650497674942\n",
      "epoch: 406, epoch_loss=0.16942161028436192, batch_loss=0.15527276694774628\n",
      "epoch: 407, epoch_loss=0.1703668700103669, batch_loss=0.15768253803253174\n",
      "epoch: 408, epoch_loss=0.16670300811351976, batch_loss=0.164548859000206\n",
      "epoch: 409, epoch_loss=0.16953896721605738, batch_loss=0.16701854765415192\n",
      "epoch: 410, epoch_loss=0.16890937602406592, batch_loss=0.1584814041852951\n",
      "epoch: 411, epoch_loss=0.16874046312501115, batch_loss=0.16421517729759216\n",
      "epoch: 412, epoch_loss=0.16800497306158654, batch_loss=0.174001082777977\n",
      "epoch: 413, epoch_loss=0.1713738984457803, batch_loss=0.16993388533592224\n",
      "epoch: 414, epoch_loss=0.16920267882018253, batch_loss=0.1638953983783722\n",
      "epoch: 415, epoch_loss=0.16845617701267374, batch_loss=0.16362783312797546\n",
      "epoch: 416, epoch_loss=0.16929406116748677, batch_loss=0.16500985622406006\n",
      "epoch: 417, epoch_loss=0.17020976242568348, batch_loss=0.16856198012828827\n",
      "epoch: 418, epoch_loss=0.16960804300557702, batch_loss=0.1589626669883728\n",
      "epoch: 419, epoch_loss=0.16845517988437422, batch_loss=0.16045495867729187\n",
      "epoch: 420, epoch_loss=0.1674954323989741, batch_loss=0.15743756294250488\n",
      "epoch: 421, epoch_loss=0.17077736405498492, batch_loss=0.155442476272583\n",
      "epoch: 422, epoch_loss=0.16886772753225637, batch_loss=0.16268417239189148\n",
      "epoch: 423, epoch_loss=0.17158484003773483, batch_loss=0.16486206650733948\n",
      "epoch: 424, epoch_loss=0.16817550144708682, batch_loss=0.15861518681049347\n",
      "epoch: 425, epoch_loss=0.16767274681934988, batch_loss=0.1643505096435547\n",
      "epoch: 426, epoch_loss=0.16911605830141538, batch_loss=0.163327157497406\n",
      "epoch: 427, epoch_loss=0.169283581932433, batch_loss=0.1596793234348297\n",
      "epoch: 428, epoch_loss=0.16871804792092898, batch_loss=0.16634850203990936\n",
      "epoch: 429, epoch_loss=0.17037591163100016, batch_loss=0.16436052322387695\n",
      "epoch: 430, epoch_loss=0.1707709164511718, batch_loss=0.15607774257659912\n",
      "epoch: 431, epoch_loss=0.17353104942902373, batch_loss=0.16329550743103027\n",
      "epoch: 432, epoch_loss=0.1667647066793884, batch_loss=0.1568605601787567\n",
      "epoch: 433, epoch_loss=0.16697273149714317, batch_loss=0.16124479472637177\n",
      "epoch: 434, epoch_loss=0.16663791351879678, batch_loss=0.15513882040977478\n",
      "epoch: 435, epoch_loss=0.16887649442437996, batch_loss=0.1607097089290619\n",
      "epoch: 436, epoch_loss=0.1658010387477353, batch_loss=0.15290915966033936\n",
      "epoch: 437, epoch_loss=0.16872738049302458, batch_loss=0.16193468868732452\n",
      "epoch: 438, epoch_loss=0.16836607190998498, batch_loss=0.15359988808631897\n",
      "epoch: 439, epoch_loss=0.17057877096565668, batch_loss=0.16354452073574066\n",
      "epoch: 440, epoch_loss=0.17227086704778047, batch_loss=0.1642053723335266\n",
      "epoch: 441, epoch_loss=0.17371515823459513, batch_loss=0.1696239709854126\n",
      "epoch: 442, epoch_loss=0.17187448261750865, batch_loss=0.16384661197662354\n",
      "epoch: 443, epoch_loss=0.17385063644396706, batch_loss=0.16633346676826477\n",
      "epoch: 444, epoch_loss=0.17240102522509276, batch_loss=0.16477860510349274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 445, epoch_loss=0.17027027958071614, batch_loss=0.16492703557014465\n",
      "epoch: 446, epoch_loss=0.16969337013331945, batch_loss=0.15517976880073547\n",
      "epoch: 447, epoch_loss=0.16830842499146137, batch_loss=0.1625850647687912\n",
      "epoch: 448, epoch_loss=0.16806474695732987, batch_loss=0.15983936190605164\n",
      "epoch: 449, epoch_loss=0.17019949227961292, batch_loss=0.1674935519695282\n",
      "epoch: 450, epoch_loss=0.1703394568462576, batch_loss=0.17214488983154297\n",
      "epoch: 451, epoch_loss=0.1702620488894255, batch_loss=0.15805640816688538\n",
      "epoch: 452, epoch_loss=0.17068066493863868, batch_loss=0.15792657434940338\n",
      "epoch: 453, epoch_loss=0.17186297608896045, batch_loss=0.16146957874298096\n",
      "epoch: 454, epoch_loss=0.17061878225253396, batch_loss=0.16053591668605804\n",
      "epoch: 455, epoch_loss=0.17345391621558476, batch_loss=0.16557835042476654\n",
      "epoch: 456, epoch_loss=0.16797143140885265, batch_loss=0.16073386371135712\n",
      "epoch: 457, epoch_loss=0.16998194441075273, batch_loss=0.1639336347579956\n",
      "epoch: 458, epoch_loss=0.17176569870904568, batch_loss=0.16285306215286255\n",
      "epoch: 459, epoch_loss=0.16956888099346093, batch_loss=0.16171890497207642\n",
      "epoch: 460, epoch_loss=0.1704557776295189, batch_loss=0.1609841287136078\n",
      "epoch: 461, epoch_loss=0.17175621403596064, batch_loss=0.16199423372745514\n",
      "epoch: 462, epoch_loss=0.17098594065370232, batch_loss=0.161662757396698\n",
      "epoch: 463, epoch_loss=0.17173671066761018, batch_loss=0.16338343918323517\n",
      "epoch: 464, epoch_loss=0.16755070010348536, batch_loss=0.1592094600200653\n",
      "epoch: 465, epoch_loss=0.16857195391382815, batch_loss=0.1627328097820282\n",
      "epoch: 466, epoch_loss=0.16772778033572344, batch_loss=0.16178558766841888\n",
      "epoch: 467, epoch_loss=0.16881628625741613, batch_loss=0.1643318235874176\n",
      "epoch: 468, epoch_loss=0.17054428567855168, batch_loss=0.16327907145023346\n",
      "epoch: 469, epoch_loss=0.16851018483800356, batch_loss=0.1606907844543457\n",
      "epoch: 470, epoch_loss=0.16522125010116206, batch_loss=0.15761509537696838\n",
      "epoch: 471, epoch_loss=0.1668455928634945, batch_loss=0.18106521666049957\n",
      "epoch: 472, epoch_loss=0.17102089793588546, batch_loss=0.1680448353290558\n",
      "epoch: 473, epoch_loss=0.1727116060455404, batch_loss=0.16015106439590454\n",
      "epoch: 474, epoch_loss=0.1690283717950374, batch_loss=0.1664571762084961\n",
      "epoch: 475, epoch_loss=0.16812843262086158, batch_loss=0.164925217628479\n",
      "epoch: 476, epoch_loss=0.1677459777507147, batch_loss=0.15607723593711853\n",
      "epoch: 477, epoch_loss=0.1658082576094286, batch_loss=0.15401996672153473\n",
      "epoch: 478, epoch_loss=0.17118794535201454, batch_loss=0.15582749247550964\n",
      "epoch: 479, epoch_loss=0.1680156960789287, batch_loss=0.16271336376667023\n",
      "epoch: 480, epoch_loss=0.16525026543245305, batch_loss=0.1596302092075348\n",
      "epoch: 481, epoch_loss=0.16828756446007742, batch_loss=0.1591959446668625\n",
      "epoch: 482, epoch_loss=0.1690897344607377, batch_loss=0.165610671043396\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m loss, temp_xt, temp_noise, temp_noise_pred \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39mget_loss(model, batch, t)\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 19\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     21\u001b[0m epoch_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\optim\\adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\optim\\adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\optim\\adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    408\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 410\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    412\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch, channel, spe = newX.shape\n",
    "model = SimpleUnet1D()\n",
    "model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.1)\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_size = 0\n",
    "    for step, (batch, _) in enumerate(all_data_loader):\n",
    "\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t = torch.randint(0, diffusion.T, (batch.shape[0],), device=device).long()\n",
    "        loss, temp_xt, temp_noise, temp_noise_pred = diffusion.get_loss(model, batch, t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += (loss.item() * batch.shape[0])\n",
    "        epoch_size += batch.shape[0]\n",
    "    \n",
    "    print(\"epoch: %s, epoch_loss=%s, batch_loss=%s\" %(epoch, epoch_loss/epoch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb0469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115cdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94244055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
